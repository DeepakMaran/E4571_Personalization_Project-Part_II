{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import surprise\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k, threshold):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "        recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "        \n",
    "        # Compute F-score\n",
    "        f_score = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "    return precision, recall, f_score\n",
    "\n",
    "\n",
    "def ndcg_at_k(predictions, k):\n",
    "    dcgs = dict()\n",
    "    idcgs = dict()\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "        \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        #estimated rank\n",
    "        rank_est = np.arange(1, len(user_ratings[:k])+1)\n",
    "        discount_est = np.log2(rank_est+1)\n",
    "        \n",
    "        #Relevance \n",
    "        rel = [np.power(2,true_r)-1 for (_, true_r) in user_ratings[:k]]\n",
    "        \n",
    "        dcgs[uid] = sum(rel/discount_est)\n",
    "        \n",
    "        # Sort user ratings by true value\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        #estimated rank\n",
    "        rank_true = np.arange(1, len(user_ratings[:k])+1)\n",
    "        discount_true = np.log2(rank_true+1)\n",
    "        \n",
    "        #Relevance \n",
    "        rel_true = [np.power(2,true_r)-1 for (_, true_r) in user_ratings[:k]]\n",
    "        \n",
    "        idcgs[uid] = sum(rel_true/discount_true)\n",
    "        \n",
    "    dcg = sum(dcgu for (_,dcgu) in dcgs.items())\n",
    "    idcg = sum(idcgu for (_,idcgu) in idcgs.items())\n",
    "    return dcg/idcg\n",
    "\n",
    "\n",
    "def user_space_coverage(predictions, k, n_user, threshold):\n",
    "\t# First map the predictions to each user.\n",
    "    user_est = defaultdict(list)\n",
    "    for uid, _, _, est, _ in predictions:\n",
    "        if est >= threshold:\n",
    "            user_est[uid].append(est)\n",
    "    n_user_k = sum((len(n_est) >= k ) for n_est in user_est.values())\n",
    "    a = n_user_k/n_user\n",
    "    return a\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "        \n",
    "    return top_n\n",
    "\n",
    "def item_space_coverage(predictions, k, n_items, threshold):\n",
    "    top_n = get_top_n(predictions, k)\n",
    "    items = []\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        for (iid, rtg) in user_ratings:\n",
    "            if rtg >= threshold:\n",
    "                items.append(iid)\n",
    "    \n",
    "    return(len(set(items))/n_items)\n",
    "\n",
    "# the items recommended to each user based on predictions\n",
    "def recommendation_list(predictions, k, threshold):\n",
    "    recom_list = defaultdict(list)\n",
    "    top_n = get_top_n(predictions, k)\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        for (iid, rating) in user_ratings:\n",
    "            if rating >= threshold:\n",
    "                recom_list[uid].append(iid)\n",
    "    return recom_list\n",
    "\n",
    "# the item popularity for each item\n",
    "def item_popularity(ratings, n_users):\n",
    "    item_pop = defaultdict(lambda: 0)\n",
    "    for uid, iid, rtg in ratings: \n",
    "        item_pop[iid] +=1\n",
    "    item_pop.update((iid, float(pop/n_users)) for iid, pop in item_pop.items())\n",
    "    return item_pop\n",
    "\n",
    "def novelty(predictions, k, item_pop, threshold):\n",
    "    '''Return novelty metrics'''\n",
    "    \n",
    "    recom_list = recommendation_list(predictions, k, threshold)\n",
    "  \n",
    "    # novelties: the novelty metrics for each user\n",
    "    novelties = dict()\n",
    "    for uid, items in recom_list.items():\n",
    "        # self_info: define novelty as the negative of the log of the item popularity\n",
    "        self_info = 0\n",
    "        for iid in items:\n",
    "            self_info += -math.log2(item_pop[iid])\n",
    "        novelties[uid] = float(self_info/len(items)) \n",
    "\n",
    "    # compute novelty\n",
    "    novelty = sum(nov for nov in novelties.values()) / len(novelties)\n",
    "\n",
    "    return novelty\n",
    "\n",
    "def serendipity(predictions, predictions_primitive, k, threshold):\n",
    "    '''Return serendipity metrics'''\n",
    "    recom_list = recommendation_list(predictions, k, threshold)\n",
    "    recom_list_prim = recommendation_list(predictions_primitive, k, threshold)\n",
    "    \n",
    "    # novelties: the serendipity metrics for each user\n",
    "    serendipities = dict()\n",
    "    for uid, items in recom_list.items():\n",
    "        # unexpected: the number of unexpected items for each user\n",
    "        n_unexpected = 0\n",
    "        for iid in items:\n",
    "            if iid not in recom_list_prim[uid]:\n",
    "                n_unexpected += 1\n",
    "        serendipities[uid] = float(n_unexpected/len(items))\n",
    "\n",
    "    # compute serendipity\n",
    "    serendipity = sum(ser for ser in serendipities.values()) / len(serendipities)\n",
    "\n",
    "    return serendipity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# user based knn\n",
    "def hybrid_switching_knn(predictions_knn, predictions_cb, threshold_knn, item_based = True):\n",
    "    if item_based == True:\n",
    "        df_knn_pred = pd.DataFrame(predictions_knn)\n",
    "        # some ratings don't have actual estimated ratings because those items don't have enough neighbors('was_impossible':True, and algs gives average ratings instead)\n",
    "        # so we only use knn to compute estimated ratings for those item that have enough neighbors \n",
    "        criterion_1 = df_knn_pred['details'].map(lambda x: x['was_impossible'] == False)\n",
    "        criterion_2 = df_knn_pred['details'][criterion_1].map(lambda x: x['actual_k'] >= threshold_knn)\n",
    "        criterion = criterion_1 & criterion_2\n",
    "        sub_knn_pred = df_knn_pred[criterion]\n",
    "        predictions = [tuple(x) for x in sub_knn_pred.values]\n",
    "\n",
    "        iid_knn = sub_knn_pred['iid'].unique()\n",
    "        predictions.extend([(uid, iid, r_ui, est, details) for uid, iid, r_ui, est, details in predictions_cb if iid not in iid_knn])\n",
    "        return predictions\n",
    "    elif item_based == False:    \n",
    "        df_knn_pred = pd.DataFrame(predictions_knn)\n",
    "        criterion = df_knn_pred['details'].map(lambda x: x['actual_k'] >= threshold_knn)\n",
    "        sub_knn_pred = df_knn_pred[criterion]\n",
    "        predictions = [tuple(x) for x in sub_knn_pred.values]\n",
    "\n",
    "        uid_knn = sub_knn_pred['uid'].unique()\n",
    "        predictions.extend([(uid, iid, r_ui, est, details) for uid, iid, r_ui, est, details in predictions_cb if uid not in uid_knn])\n",
    "        return predictions\n",
    "    \n",
    "    else:\n",
    "        print('Error: input for item_based')\n",
    "        return 0 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hybrid_switching_svd(predictions_svd, predictions_cb, threshold_svd):\n",
    "    # use content-based model when the number of available ratings of a user falls below a fixed threshold\n",
    "    # Ids that we apply Matrix Factorization method to recommend books\n",
    "    uid_svd = pd.DataFrame(predictions_svd).groupby('uid').filter(lambda x: len(x) >= threshold_svd)['uid'].unique()\n",
    "    predictions = [(uid, iid, r_ui, est, details) for uid, iid, r_ui, est, details in predictions_svd if uid in uid_svd]\n",
    "    predictions.extend([(uid, iid, r_ui, est, details) for uid, iid, r_ui, est, details in predictions_cb if uid not in uid_svd])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hybrid_mixed(predictions_cf, predictions_cb, n_cf, n_cb):\n",
    "    # choose top n_cf estimated ratings from predictions_cf\n",
    "    sub_cf_pred = pd.DataFrame(predictions_cf).groupby('uid').apply(lambda x: x.nlargest(n_cf, 'est')).reset_index(drop=True)\n",
    "    # choose top n_cb estimated ratings from predictions_cb\n",
    "    sub_cb_pred = pd.DataFrame(predictions_cb).groupby('uid').apply(lambda x: x.nlargest(n_cb, 'est')).reset_index(drop=True)\n",
    "    predictions_df = sub_cf_pred.iloc[:,0:4].merge(sub_cb_pred.iloc[:,0:4], how='outer')\n",
    "    predictions_df['details'] = 0\n",
    "    predictions = [tuple(x) for x in predictions_df.values]\n",
    "    return predictions\n",
    "    # Note there might be problem with metrics since we only have n_cf+n_cb predictions for each user now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hybrid_weighted(predictions_cf, predictions_cb, alpha):\n",
    "    predictions_df = pd.merge(pd.DataFrame(predictions_cf, columns = ['uid', 'iid', 'r_ui', 'est_cf', 'details_cf']), \n",
    "                              pd.DataFrame(predictions_cb, columns = ['uid', 'iid', 'r_ui', 'est_cb', 'details_cb']), \n",
    "                              how='inner', on=['uid', 'iid', 'r_ui'])\n",
    "    predictions_df['est'] = alpha*predictions_df['est_cf'] + (1-alpha)*predictions_df['est_cb']\n",
    "    predictions_df = predictions_df.drop(['est_cf', 'est_cb', 'details_cf', 'details_cb'], axis=1)\n",
    "    predictions_df['details'] = 0\n",
    "    predictions = [tuple(x) for x in predictions_df.values]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "n_items_train = len(np.unique(train['ISBN']))\n",
    "n_users_train = len(np.unique(train['User-ID']))\n",
    "\n",
    "reader = surprise.Reader(rating_scale=(1, 10))\n",
    "data = surprise.Dataset.load_from_df(train[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "trainset= data.build_full_trainset()\n",
    "item_pop_train = item_popularity(trainset.build_testset(), n_users_train)\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "n_items_test = len(np.unique(test['ISBN']))\n",
    "n_users_test = len(np.unique(train['User-ID']))\n",
    "t = [tuple(x) for x in test[['User-ID', 'ISBN', 'Book-Rating']].values]\n",
    "item_pop_test = item_popularity(t, n_users_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "\n",
      " Baseline Test Set:\n",
      " Precision:0.7567175847474973\n",
      " Recall:0.98956254621546\n",
      " F-Score:0.8576165606555032\n",
      " NDCG:0.9344864959697291\n",
      " Item-space coverage:0.9199113643558088\n",
      " User-space coverage:0.002967359050445104\n",
      " Novelty:11.96056009989232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "algo_baseline = surprise.BaselineOnly()\n",
    "# retrain on the whole train set\n",
    "algo_baseline.train(trainset)\n",
    "'''\n",
    "# Compute biased accuracy on train set\n",
    "predictions_base_train= algo_baseline.test(trainset.build_testset())\n",
    "precision_base_train, recall_base_train, f_base_train = precision_recall_at_k(predictions_base_train, k=10, threshold=7)\n",
    "print (\"\\n Baseline Training Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n\".format(precision_base_train, recall_base_train, f_base_train, \n",
    "    ndcg_at_k(predictions_base_train, 10),\n",
    "    item_space_coverage(predictions_base_train, 10, n_items_train,7),\n",
    "    user_space_coverage(predictions_base_train, 10, n_users_train,7),\n",
    "    novelty(predictions_base_train, 10, item_pop_train, 7)))\n",
    "'''\n",
    "# Compute unbiased accuracy on test set\n",
    "predictions_base_test = algo_baseline.test(t)\n",
    "precision_base_test, recall_base_test, f_base_test = precision_recall_at_k(predictions_base_test, k=10, threshold=7)\n",
    "print (\"\\n Baseline Test Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n\".format(precision_base_test, recall_base_test, f_base_test, \n",
    "    ndcg_at_k(predictions_base_test, 10),\n",
    "    item_space_coverage(predictions_base_test, 10, n_items_test,7), \n",
    "    user_space_coverage(predictions_base_test, 10, n_users_test,7),\n",
    "    novelty(predictions_base_test, 10, item_pop_test, 7)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prdictions from content based model has been saved into predictions_cb.csv\n",
    "predictions_cb_test= pd.read_csv('predictions_cb.csv')\n",
    "predictions_cb_test.columns = ['uid', 'iid', 'r_ui', 'est', 'details']\n",
    "predictions_cb_test = [x for x in predictions_cb_test.itertuples(index = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Content Based on Test Set:\n",
      " Precision:0.8411380436651194\n",
      " Recall:0.5642715270422853\n",
      " F-Score:0.6754333515935501\n",
      " NDCG:0.9077613212125732\n",
      " Item-space coverage:0.4491927825261159\n",
      " User-space coverage:0.000635862653666808\n",
      " Novelty:12.123808458894143\n",
      " Serendipity:0.018027558671730448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision_cb_test, recall_cb_test, f_cb_test = precision_recall_at_k(predictions_cb_test, k=10, threshold=7)\n",
    "print (\"\\n Content Based on Test Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_cb_test, recall_cb_test, f_cb_test, \n",
    "    ndcg_at_k(predictions_cb_test, 10),\n",
    "    item_space_coverage(predictions_cb_test, 10, n_items_test,7),\n",
    "    user_space_coverage(predictions_cb_test, 10, n_users_test,7),\n",
    "    novelty(predictions_cb_test, 10, item_pop_test, 7),\n",
    "    serendipity(predictions_cb_test, predictions_base_test, 10, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      " KNN on Test Set:\n",
      " Precision:0.7469111471303325\n",
      " Recall:0.9977161491339762\n",
      " F-Score:0.8542859727757216\n",
      " NDCG:0.9181076071711439\n",
      " Item-space coverage:0.9487179487179487\n",
      " User-space coverage:0.0036032217041119118\n",
      " Novelty:11.957994993395376\n",
      " Serendipity:0.017960288808664262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "sim_options = {'name': 'pearson',\n",
    "               'user_based': False\n",
    "               }\n",
    "algo_knn = surprise.KNNBasic(k=5, sim_options=sim_options)\n",
    "# retrain on the whole train set\n",
    "algo_knn.train(trainset)\n",
    "'''\n",
    "# Compute biased accuracy on train set\n",
    "predictions_knn_train = algo_knn.test(trainset.build_testset())\n",
    "precision_knn_train, recall_knn_train, f_knn_train = precision_recall_at_k(predictions_knn_train, k=10, threshold=7)\n",
    "print (\"\\n KNN on Training Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_knn_train, recall_knn_train, f_knn_train, \n",
    "    ndcg_at_k(predictions_knn_train, 10),\n",
    "    item_space_coverage(predictions_knn_train, 10, n_items_train,7),\n",
    "    user_space_coverage(predictions_knn_train, 10, n_users_train,7),\n",
    "    novelty(predictions_knn_train, 10, item_pop_train, 7),\n",
    "    serendipity(predictions_knn_train, predictions_base_train, 10, 7)))\n",
    "'''\n",
    "# Compute unbiased accuracy on test set\n",
    "predictions_knn_test = algo_knn.test(t)\n",
    "precision_knn_test, recall_knn_test, f_knn_test = precision_recall_at_k(predictions_knn_test, k=10, threshold=7)\n",
    "print (\"\\n KNN on Test Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_knn_test, recall_knn_test, f_knn_test, \n",
    "    ndcg_at_k(predictions_knn_test, 10),\n",
    "    item_space_coverage(predictions_knn_test, 10, n_items_test,7), \n",
    "    user_space_coverage(predictions_knn_test, 10, n_users_test,7),\n",
    "    novelty(predictions_knn_test, 10, item_pop_test, 7),\n",
    "    serendipity(predictions_knn_test, predictions_base_test, 10, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HS KNN on Test Set:\n",
      " Precision:0.8411380436651194\n",
      " Recall:0.5642822714122353\n",
      " F-Score:0.6754410488572925\n",
      " NDCG:0.907916482933468\n",
      " Item-space coverage:0.4491927825261159\n",
      " User-space coverage:0.000635862653666808\n",
      " Novelty:12.123808458894143\n",
      " Serendipity:0.018027558671730448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tunning on threshold\n",
    "#thresholds_knn = [0,1,2,3,4]\n",
    "#for threshold_knn in thresholds_knn:\n",
    "#    print ('\\n threshold:{}'.format(threshold_knn))\n",
    "threshold_knn = 2\n",
    "'''\n",
    "predictions_knn_hs_train = hybrid_switching_knn(predictions_knn_train, predictions_cb_train, threshold_knn, item_based = True)\n",
    "precision_knn_hs_train, recall_knn_hs_train, f_knn_hs_train = precision_recall_at_k(predictions_knn_hs_train, k=10, threshold=7)\n",
    "print (\"\\n HS KNN on Training Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_knn_hs_train, recall_knn_hs_train, f_knn_hs_train, \n",
    "    ndcg_at_k(predictions_knn_hs_train, k=10),\n",
    "    item_space_coverage(predictions_knn_hs_train, 10, n_items_train,7), \n",
    "    user_space_coverage(predictions_knn_hs_train, 10, n_users_train,7),\n",
    "    novelty(predictions_knn_hs_train, 10, item_pop_train, 7),\n",
    "    serendipity(predictions_knn_hs_train, predictions_baseline_train, 10, 7)))\n",
    "'''\n",
    "predictions_knn_hs_test = hybrid_switching_knn(predictions_knn_test, predictions_cb_test, threshold_knn, item_based = True)\n",
    "precision_knn_hs_test, recall_knn_hs_test, f_knn_hs_test = precision_recall_at_k(predictions_knn_hs_test, k=10, threshold=7)\n",
    "print (\"\\n HS KNN on Test Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_knn_hs_test, recall_knn_hs_test, f_knn_hs_test, \n",
    "    ndcg_at_k(predictions_knn_hs_test, 10),\n",
    "    item_space_coverage(predictions_knn_hs_test, 10, n_items_test,7), \n",
    "    user_space_coverage(predictions_knn_hs_test, 10, n_users_test,7),\n",
    "    novelty(predictions_knn_hs_test, 10, item_pop_test, 7),\n",
    "    serendipity(predictions_knn_hs_test, predictions_base_test, 10, 7)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HW KNN on Test Set:\n",
      " Precision:0.818009610583102\n",
      " Recall:0.6278214133487472\n",
      " F-Score:0.710406598486918\n",
      " NDCG:0.9078110459296956\n",
      " Item-space coverage:0.5254827477049699\n",
      " User-space coverage:0.000847816871555744\n",
      " Novelty:12.11403218616194\n",
      " Serendipity:0.016480067854113656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tunning on alpha\n",
    "#alphas_knn = [0.2, 0.4, 0.6, 0.8]\n",
    "#for alpha_knn in alphas_knn:\n",
    "#    print ('\\n alpha:{}'.format(alpha_knn))\n",
    "alpha_knn = 0.5\n",
    "'''\n",
    "predictions_knn_hw_train = hybrid_weighted(predictions_knn_train, predictions_cb_train, alpha_knn)\n",
    "precision_knn_hw_train, recall_knn_hw_train, f_knn_hw_train = precision_recall_at_k(predictions_knn_hw_train, k=10, threshold=7)\n",
    "print (\"\\n HW KNN on Training Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_knn_hw_train, recall_knn_hw_train, f_knn_hw_train, \n",
    "    ndcg_at_k(predictions_knn_hw_train, k=10),\n",
    "    item_space_coverage(predictions_knn_hw_train, 10, n_items_train,7), \n",
    "    user_space_coverage(predictions_knn_hw_train, 10, n_users_train,7),\n",
    "    novelty(predictions_knn_hw_train, 10, item_pop_train, 7),\n",
    "    serendipity(predictions_knn_hw_train, predictions_baseline_train, 10, 7)))\n",
    "'''\n",
    "predictions_knn_hw_test = hybrid_weighted(predictions_knn_test, predictions_cb_test, alpha_knn)\n",
    "precision_knn_hw_test, recall_knn_hw_test, f_knn_hw_test = precision_recall_at_k(predictions_knn_hw_test, k=10, threshold=7)\n",
    "print (\"\\n HW KNN on Test Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_knn_hw_test, recall_knn_hw_test, f_knn_hw_test, \n",
    "    ndcg_at_k(predictions_knn_hw_test, 10),\n",
    "    item_space_coverage(predictions_knn_hw_test, 10, n_items_test,7), \n",
    "    user_space_coverage(predictions_knn_hw_test, 10, n_users_test,7),\n",
    "    novelty(predictions_knn_hw_test, 10, item_pop_test, 7),\n",
    "    serendipity(predictions_knn_hw_test, predictions_base_test, 10, 7)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HM KNN on Test Set:\n",
      " Precision:0.746691348019352\n",
      " Recall:0.7797254728684226\n",
      " F-Score:0.7628509545414067\n",
      " NDCG:0.8993491519116403\n",
      " Item-space coverage:0.9392212725546059\n",
      " User-space coverage:0.009961848240779992\n",
      " Novelty:11.967603272416541\n",
      " Serendipity:0.017942893162078314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_knn = 10\n",
    "n_cb = 10\n",
    "'''\n",
    "predictions_knn_hm_train = hybrid_mixed(predictions_knn_train, predictions_cb_train, n_knn, n_cb)\n",
    "precision_knn_hm_train, recall_knn_hm_train, f_knn_hm_train = precision_recall_at_k(predictions_knn_hm_train, k=10, threshold=7)\n",
    "print (\"\\n HM KNN on Training Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_knn_hm_train, recall_knn_hm_train, f_knn_hm_train, \n",
    "    ndcg_at_k(predictions_knn_hm_train, 10), \n",
    "    item_space_coverage(predictions_knn_hm_train, 10, n_items_train,7), \n",
    "    user_space_coverage(predictions_knn_hm_train, 10, n_users_train,7),\n",
    "    novelty(predictions_knn_hm_train, 10, item_pop_train, 7),\n",
    "    serendipity(predictions_knn_hm_train, predictions_base_train, 10, 7)))\n",
    "'''\n",
    "predictions_knn_hm_test = hybrid_mixed(predictions_knn_test, predictions_cb_test, n_knn, n_cb)\n",
    "precision_knn_hm_test, recall_knn_hm_test, f_knn_hm_test = precision_recall_at_k(predictions_knn_hm_test, k=10, threshold=7)\n",
    "print (\"\\n HM KNN on Test Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_knn_hm_test, recall_knn_hm_test, f_knn_hm_test, \n",
    "    ndcg_at_k(predictions_knn_hm_test, 10), \n",
    "    item_space_coverage(predictions_knn_hm_test, 10, n_items_test,7), \n",
    "    user_space_coverage(predictions_knn_hm_test, 10, n_users_test,7),\n",
    "    novelty(predictions_knn_hm_test, 10, item_pop_test, 7),\n",
    "    serendipity(predictions_knn_hm_test, predictions_base_test, 10, 7)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SVD on Test Set:\n",
      " Precision:0.7478394606940252\n",
      " Recall:0.9966071482398626\n",
      " F-Score:0.8544854837592284\n",
      " NDCG:0.9322728143489497\n",
      " Item-space coverage:0.940804051915163\n",
      " User-space coverage:0.00317931326833404\n",
      " Novelty:11.95756472330265\n",
      " Serendipity:0.015397521941146101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVD\n",
    "algo_svd = surprise.SVD(n_factors = 10, lr_all= 0.001, reg_all =1)\n",
    "# retrain on the whole train set\n",
    "algo_svd.train(trainset)\n",
    "'''\n",
    "# Compute biased accuracy on train set\n",
    "predictions_svd_train = algo_svd.test(trainset.build_testset())\n",
    "precision_svd_train, recall_svd_train, f_svd_train = precision_recall_at_k(predictions_svd_train, k=10, threshold=7)\n",
    "print (\"\\n SVD on Training Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_svd_train, recall_svd_train, f_svd_train, \n",
    "    ndcg_at_k(predictions_svd_train, 10),\n",
    "    item_space_coverage(predictions_svd_train, 10, n_items_train,7),\n",
    "    user_space_coverage(predictions_svd_train, 10, n_users_train,7),\n",
    "    novelty(predictions_svd_train, 10, item_pop_train, 7),\n",
    "    serendipity(predictions_svd_train, predictions_base_train, 10, 7)))\n",
    "'''\n",
    "# Compute unbiased accuracy on test set\n",
    "predictions_svd_test = algo_svd.test(t)\n",
    "precision_svd_test, recall_svd_test, f_svd_test = precision_recall_at_k(predictions_svd_test, k=10, threshold=7)\n",
    "print (\"\\n SVD on Test Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_svd_test, recall_svd_test, f_svd_test, \n",
    "    ndcg_at_k(predictions_svd_test, 10),\n",
    "    item_space_coverage(predictions_svd_test, 10, n_items_test,7),\n",
    "    user_space_coverage(predictions_svd_test, 10, n_users_test,7),\n",
    "    novelty(predictions_svd_test, 10, item_pop_test, 7),\n",
    "    serendipity(predictions_svd_test, predictions_base_test, 10, 7)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HS SVD on Test Set:\n",
      " Precision:0.8409716594218912\n",
      " Recall:0.6015581539128902\n",
      " F-Score:0.7013974397733787\n",
      " NDCG:0.9173957450187944\n",
      " Item-space coverage:0.5834124723013612\n",
      " User-space coverage:0.00317931326833404\n",
      " Novelty:12.096654458345066\n",
      " Serendipity:0.014303266840127204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold_svd = 5\n",
    "'''\n",
    "predictions_svd_hs_train = hybrid_switching_svd(predictions_svd_train, predictions_cb_train, threshold_svd)\n",
    "precision_svd_hs_train, recall_svd_hs_train, f_svd_hs_train= precision_recall_at_k(predictions_svd_hs_train, k=10, threshold=7)\n",
    "print (\"\\n HS SVD on Training Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_svd_hs_train, recall_svd_hs_train, f_svd_hs_train, \n",
    "    ndcg_at_k(predictions_svd_hs_train, 10), \n",
    "    item_space_coverage(predictions_svd_hs_train, 10, n_items_train,7), \n",
    "    user_space_coverage(predictions_svd_hs_train, 10, n_users_train,7),\n",
    "    novelty(predictions_svd_hs_train, 10, item_pop_train, 7),\n",
    "    serendipity(predictions_svd_hs_train, predictions_base_train, 10, 7)))\n",
    "'''\n",
    "predictions_svd_hs_test = hybrid_switching_svd(predictions_svd_test, predictions_cb_test, threshold_svd)\n",
    "precision_svd_hs_test, recall_svd_hs_test, f_svd_hs_test = precision_recall_at_k(predictions_svd_hs_test, k=10, threshold=7)\n",
    "print (\"\\n HS SVD on Test Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_svd_hs_test, recall_svd_hs_test, f_svd_hs_test, \n",
    "    ndcg_at_k(predictions_svd_hs_test, 10), \n",
    "    item_space_coverage(predictions_svd_hs_test, 10, n_items_test,7), \n",
    "    user_space_coverage(predictions_svd_hs_test, 10, n_users_test,7),\n",
    "    novelty(predictions_svd_hs_test, 10, item_pop_test, 7),\n",
    "    serendipity(predictions_svd_hs_test, predictions_base_test, 10, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HW SVD on Test Set:\n",
      " Precision:0.8179482141833868\n",
      " Recall:0.6263601790355272\n",
      " F-Score:0.7094470852390069\n",
      " NDCG:0.9088161475120767\n",
      " Item-space coverage:0.5242165242165242\n",
      " User-space coverage:0.000847816871555744\n",
      " Novelty:12.112717357548464\n",
      " Serendipity:0.015828654075208438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha_svd = 0.5\n",
    "'''\n",
    "predictions_svd_hw_train = hybrid_weighted(predictions_svd_train, predictions_cb_train, alpha_svd)\n",
    "precision_svd_hw_train, recall_svd_hw_train, f_svd_hw_train= precision_recall_at_k(predictions_svd_hw_train, k=10, threshold=7)\n",
    "print (\"\\n HW SVD on Training Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_svd_hw_train, recall_svd_hw_train, f_svd_hw_train, \n",
    "    ndcg_at_k(predictions_svd_hw_train, 10), \n",
    "    item_space_coverage(predictions_svd_hw_train, 10, n_items_train,7), \n",
    "    user_space_coverage(predictions_svd_hw_train, 10, n_users_train,7),\n",
    "    novelty(predictions_svd_hw_train, 10, item_pop_train, 7),\n",
    "    serendipity(predictions_svd_hw_train, predictions_base_train, 10, 7)))\n",
    "'''\n",
    "predictions_svd_hw_test = hybrid_weighted(predictions_svd_test, predictions_cb_test, alpha_svd)\n",
    "precision_svd_hw_test, recall_svd_hw_test, f_svd_hw_test = precision_recall_at_k(predictions_svd_hw_test, k=10, threshold=7)\n",
    "print (\"\\n HW SVD on Test Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_svd_hw_test, recall_svd_hw_test, f_svd_hw_test, \n",
    "    ndcg_at_k(predictions_svd_hw_test, 10), \n",
    "    item_space_coverage(predictions_svd_hw_test, 10, n_items_test,7), \n",
    "    user_space_coverage(predictions_svd_hw_test, 10, n_users_test,7),\n",
    "    novelty(predictions_svd_hw_test, 10, item_pop_test, 7),\n",
    "    serendipity(predictions_svd_hw_test, predictions_base_test, 10, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HM SVD on Test Set:\n",
      " Precision:0.7466569660355115\n",
      " Recall:0.7791450648281354\n",
      " F-Score:0.7625551394460109\n",
      " NDCG:0.9044584788993925\n",
      " Item-space coverage:0.9404874960430516\n",
      " User-space coverage:0.009749894022891056\n",
      " Novelty:11.968201079490822\n",
      " Serendipity:0.01722087150142849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_svd = 10\n",
    "n_cb = 10\n",
    "'''\n",
    "predictions_svd_hm_train = hybrid_mixed(predictions_svd_train, predictions_cb_train, n_svd, n_cb)\n",
    "precision_svd_hm_train, recall_svd_hm_train, f_svd_hm_train = precision_recall_at_k(predictions_svd_hm_train, k=10, threshold=7)\n",
    "print (\"\\n HM SVD on Training Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_svd_hm_train, recall_svd_hm_train, f_svd_hm_train, \n",
    "    ndcg_at_k(predictions_svd_hm_train, 10),\n",
    "    item_space_coverage(predictions_svd_hm_train, 10, n_items_train,7),\n",
    "    user_space_coverage(predictions_svd_hm_train, 10, n_users_train,7),\n",
    "    novelty(predictions_svd_hm_train, 10, item_pop_train, 7),\n",
    "    serendipity(predictions_svd_hm_train, predictions_base_train, 10, 7)))\n",
    "'''\n",
    "predictions_svd_hm_test = hybrid_mixed(predictions_svd_test, predictions_cb_test, n_svd, n_cb)\n",
    "precision_svd_hm_test, recall_svd_hm_test, f_svd_hm_test = precision_recall_at_k(predictions_svd_hm_test, k=10, threshold=7)\n",
    "print (\"\\n HM SVD on Test Set:\\n Precision:{}\\n Recall:{}\\n F-Score:{}\\n NDCG:{}\\n Item-space coverage:{}\\n User-space coverage:{}\\n Novelty:{}\\n Serendipity:{}\\n\".format(precision_svd_hm_test, recall_svd_hm_test, f_svd_hm_test, \n",
    "    ndcg_at_k(predictions_svd_hm_test, 10),\n",
    "    item_space_coverage(predictions_svd_hm_test, 10, n_items_test,7), \n",
    "    user_space_coverage(predictions_svd_hm_test, 10, n_users_test,7),\n",
    "    novelty(predictions_svd_hm_test, 10, item_pop_test, 7),\n",
    "    serendipity(predictions_svd_hm_test, predictions_base_test, 10, 7)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
